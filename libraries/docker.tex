\section{Docker}

\subsection{When would you want to use docker?}
When you have one host that hosts many processes that are all linux-based, but for the rest should be isolated. 

\subsection{Containers}

\begin{itemize}
    \item an \emph{image} is an executable package that includes everything needed to run an application--the code, a runtime, libraries, environment variables, and configuration files.
    \item a \emph{container} is a runtime instance of an image - what the image becomes in memory when executed (that is, an image with state, or a user process).
\end{itemize}


Containers and virtual machines.
\begin{itemize}
    \item A container runs natively on Linux and shares the kernel of the host machine with other containers. It runs a discrete process, taking no more memory than any other executable, making it lightweight.
    \item By contrast, a virtual machine (VM) runs a full-blown “guest” operating system with virtual access to host resources through a hypervisor. In general, VMs provide an environment with more resources than most applications need.
\end{itemize}

Images are described by \emph{Dockerfiles} that list all the contents of an image. These image files can be downloaded from a central repository called \emph{docker hub}.
Usually, you write your own dockerfile that specifies as a dependency a more general dockerfile as your base. 

\begin{lstlisting}[language=bash]
# Use an official Python runtime as a parent image
FROM python:2.7-slim

# Set the working directory to /app
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY . /app

# Install any needed packages specified in requirements.txt
RUN pip install --trusted-host pypi.python.org -r requirements.txt

# Make port 80 available to the world outside this container
EXPOSE 80

# Define environment variable
ENV NAME World

# Run app.py when the container launches
CMD ["python", "app.py"]
\end{lstlisting}

You then write your app. 
\begin{lstlisting}[caption=requirements.txt]
Flask
Redis
\end{lstlisting}

\begin{lstlisting}[language=python, caption=main.py]
    from flask import Flask
    from redis import Redis, RedisError
    import os
    import socket
    
    # Connect to Redis
    redis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)
    
    app = Flask(__name__)
    
    @app.route("/")
    def hello():
        try:
            visits = redis.incr("counter")
        except RedisError:
            visits = "<i>cannot connect to Redis, counter disabled</i>"
    
        html = "<h3>Hello {name}!</h3>" \
               "<b>Hostname:</b> {hostname}<br/>" \
               "<b>Visits:</b> {visits}"
        return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)
    
    if __name__ == "__main__":
        app.run(host='0.0.0.0', port=80)
\end{lstlisting}
Then you package your app and send it to \inlinecode{/var/lib/docker/images} by calling \inlinecode{sudo docker image build --tag=<nameofyourappalllowercase> .}
Then you execute that package by calling \inlinecode{sudo docker container run -p 4000:80 -d --name=<nameofyourcontaineralllowercase> <nameofyourappalllowercase>} (where \inlinecode{-p 4000:80} means \emph{map the containers port 80 to the systems port 4000} and \inlinecode{-d} stands for \emph{detached}, i.e. get back control of your command-line after starting the container).


\subsection{Services and docker-compose}

A service is a group of containers of the same image. Where \inlinecode{docker} creates a container from a \inlinecode{Dockerfile}, the program \inlinecode{docker-compose} creates a service from a \inlinecode{docker-compose.yml} file. 

Services allow you to scale containers across multiple Docker daemons, which all work together as a swarm with multiple managers and workers. Each member of a swarm is a Docker daemon, and the daemons all communicate using the Docker API. A service allows you to define the desired state, such as the number of replicas of the service that must be available at any given time. By default, the service is load-balanced across all worker nodes. To the consumer, the Docker service appears to be a single application. 
To set up a service, provide a \inlinecode{docker-compose.yml} file.

\begin{lstlisting}
    version: "3"
    services: 
        web: 
            image: username/repo:tag
            deploy: 
                replicas: 5
                resources:
                    limits: 
                        cpus: "0.1"
                        memory: 50M
                restart_policy: 
                    condition: on-failure
            ports: 
                - "4000:80"
            networks: 
                - webnet
    networks: 
        webnet:
        
\end{lstlisting}

This docker-compose.yml file tells Docker to do the following:
\begin{itemize}
    \item Pull the image we uploaded in step 2 from the registry.
    \item Run 5 instances of that image as a service called web, limiting each one to use, at most, 10\% of a single core of CPU time (this could also be e.g. “1.5” to mean 1 and half core for each), and 50MB of RAM.
    \item Immediately restart containers if one fails.
    \item Map port 4000 on the host to web’s port 80.
    \item Instruct web’s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves publish to web’s port 80 at an ephemeral port.)
    \item Define the webnet network with the default settings (which is a load-balanced overlay network).
\end{itemize}





