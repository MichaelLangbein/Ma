\section{Combinatorics}

\subsection{Sums and asymptotics}

We begin with a few trivial results. Closed form on the right. The methods we develop for sums will also work for products, since any product can be converted into a sum by taking its logarithm.

$$ \sum_{n=0}^N n = \frac{N(N+1)}{2} $$

$$ \sum_{n=0}^N x^n = \frac{1-x^{N+1}}{1-x} $$

We might get to these results with the perturbation method:

\begin{itemize}
    \item $ 1 + x + x^2 ... + x^N = S $
    \item $ -x -x^2 ... -x^{N+1} = -xS $
    \item $ 1 - x^{N+1} = S -xS $
\end{itemize}

It is very important to note that this method only works for calculating \textit{finite} partial sums. Nothing guarantees us that such a method would work as well for infinite sums. In fact, we can disprove this.

\begin{theorem}
    A example where using the perturbation method on infinite series leads to a contradiction would be ...
\end{theorem}


However, we are always allowed to calculate a partial sum by some variant of the perturbation method and then taking the limit of $n \to \infty$.

\subsection{Products of sums and convolutions}

Let $S_A = \sum_n a_n$ and $S_B = \sum_m b_n$. To calculate $S_A S_B$ we sum all elements in the following table: 

\begin{table}[H]
\centering
\caption{Multiplication of sums}
\begin{tabular}{lllll}
     & $a_0$      & $a_1$      & $a_2$      & $a_3$ \\
$b_0$ & $a_0 b_0$ & $a_1 b_0$ & $a_2 b_0$ & ...  \\
$b_1$ & $a_0 b_1$ & $a_1 b_1$ & ...       &      \\
$b_2$ & $a_0 b_2$ & ...       &           &      \\
$b_3$ & ...       &           &           &     
\end{tabular}
\end{table}

Note that the diagonal from ll to ur in this table is a convolution. 

\subsection{Cardinality}


\subsection{Counting}

\paragraph{Permutations} are the number of rearrangements where order matters. Safe-combinations should really be called safe permutations. Permutations of unique items are relatively straightforward, but things get a little involved when we deal with permutations of grouped items. 

\begin{itemize}
    \item with repetition (\emph{4-slot lock}): $n^4$
    \item without repetition (\emph{first 3 places in race}): $\frac{n!}{(n-3)!}$
\end{itemize}

The number of unique permutations of a string consisting of $n_a$ \emph{a}'s, $n_b$ \emph{b}'s, $n_c$ \emph{c}'s, etc. is 
$$ \frac{( \sum n_i )!}{\prod (n_i !)} $$
Here, $( \sum n_i )! $ is the number of permutations if every letter in the string was unique, that is, if we could distinguish between two \emph{a}'s. We then reduce this number by the number of duplicates by dividing through $n_a !$, the number of rearrangements of \emph{a}'s.

Note how the binomial coefficient is a special case of our string-permutation: it is the number of unique permutations in a string of length $n$ with only two letters in it. 
In fact, the number of string-permutations is called the \emph{multi}nomial coefficient. The formula is easily proven by induction on the number of groups $i$. In the base-case with two groups we trivially get the binomial coefficient. Then do the induction step. 

\paragraph{Combinations} are sets where the order does \emph{not} matter: $(2, 4, 3) = (2, 3, 4) = (3, 2, 4) = ...$.
\begin{itemize}
    \item without repetition (\emph{lottery of 6}): $\frac{n!}{(n-6)!6!} = {n \choose 6}$, aka. the \emph{binomial coefficient}, aka. $n$ choose $k$. Note the term $6!$ in the denominator. $n$ choose $k$ is exactly a permutation without repetition (that is, where order matters), reduced by the different ways to order things ($6!$).
    \item with repetition (\emph{draw 5 coins out of your pocket}): ${(n - 1 + 5) \choose 5}$, where $n$ is the number of different coin-denominations. Its pretty cool how this formula is obtained: write all coin-denominations in a list. Under that list, write a program, consisting of arrows for moving right and $x$'es for picking once. This is the same as picking 5 slots for $x$'es out of $(n - 1 + 5)$.
\end{itemize}



\subsection{Generating functions}

In the previous section we have found a bunch of formulas for getting the possible selections in different simple situations. But what if we need to combine a few simple selection-scenarios into one complicated scenario? \marginnote{There is another scenario where generating functions come in very handy: finding a closed form for a recursive formula.}

Imagine you need to buy n items. There are two kinds of items: apples and bananas. Apples always come in packs of six, and bananas have two different sub-kinds. How many ways are there then to get n items?

This is where we use generating functions. 


Algebraically, what's happening is that taking an ordinary generating function is a bijection between the vector space of sequences and the ring of formal power series. While in a vector space we have vector addition and scalar multiplication, in a ring we have element addition and element multiplication (and even division and differentiation!). So working in the powerseries-ring allows for ohter operations than working in the series-vectorspace. This is very simmilar to what we do when doing the Fourier-transform: we dive into a different domain where some operations are easier to do. However, Fourier is merely a change of basis, going from one vector space to another. Here, we move from a vector space to a ring - a whole different universe. 



Let $A = (a_0, a_1, ...)$ be a sequence where $a_n$ represents the number of ways to select from group $\mathcal{A}$. Then the generating function $G_A$ would be defined as: 

$$ G_A (x) = a_0 + a_1 x + a_2 x^2 + ... = \sum_n a_n x^n $$

For any sequence we can define a generating function. Now, to get the desired result, we first transform several sequences into their generating functions, find their closed forms, multiply them, and transform the result of the multiplication back into a sequence. 

In detail: 

\begin{itemize}
    \item From $(a_0, a_1, ...)$ create $G_A(x)$ and find its closed form.
    \item From $(b_0, b_1, ...)$ create $G_B(x)$ and find its closed form.
    \item Get $G_C = G_A G_B$
    \item Get $(c_0, c_1, ...)$ from $G_C$
\end{itemize}

This works because of the following theorem:

\begin{theorem}[Convolutions with generating functions]
    Let $A = (a_0, a_1, ...)$ be a sequence where $a_n$ represents the number of ways to select from group $\mathcal{A}$. Let $B = (b_0, b_1, ...)$ be a sequence where $b_n$ represents the number of ways to select from group $\mathcal{B}$. Let $\mathcal{A} \cap \mathcal{B} = \emptyset$. Then $c_n$ is the number of ways to select n items from $\mathcal{A} \cup \mathcal{B}$. It can be obtained by getting the $n$-th coefficient of $G_C = G_A G_B$
\end{theorem}

